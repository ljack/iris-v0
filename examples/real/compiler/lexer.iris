;; Compiler module: lexer/tokenizer from source text.
;; Part of the Iris compiler pipeline in examples/real/compiler.
(program
  (module (name "lexer") (version 1))
  (imports
    (import "io" (as "io"))
    (import "str" (as "str"))
    (import "list" (as "list"))
    (import "ast" (as "ast"))
  )
  (defs
    ;; Token Structure: record kind Str, value Str
    ;; Kinds: "LPAREN", "RPAREN", "INT", "STR", "IDENT", "KEYWORD", "EOF"

    (deffn (name mk_token) (args (kind Str) (value Str)) (ret ast.Token) (eff !Pure)
      (body (record (kind kind) (value value)))
    )

    (deffn (name is_digit) (args (c I64)) (ret Bool) (eff !Pure)
      (body (&& (>= c 48) (<= c 57)))
    )

    (deffn (name is_alpha) (args (c I64)) (ret Bool) (eff !Pure)
      (body (|| (&& (>= c 97) (<= c 122)) ;; a-z
                (&& (>= c 65) (<= c 90)))) ;; A-Z
    )

    (deffn (name is_whitespace) (args (c I64)) (ret Bool) (eff !Pure)
      (body (|| (= c 32) (|| (= c 10) (|| (= c 9) (= c 13))))) ;; space, \n, \t, \r
    )

    ;; Scan an integer starting at pos
    (deffn (name scan_int_loop) (args (input Str) (len I64) (start I64) (curr I64)) (ret (Tuple I64 Str)) (eff !Pure)
      (body 
        (if (>= curr len)
            (tuple curr (str.substring input start curr))
            (match (str.get input curr)
                    (case (tag "Some" (c))
                        (if (is_digit c)
                            (scan_int_loop input len start (+ curr 1))
                            (tuple curr (str.substring input start curr))
                        )
                    )
                    (case (tag "None") (tuple curr (str.substring input start curr)))
            )
        )
      )
    )

    (deffn (name scan_int) (args (input Str) (len I64) (start I64)) (ret (Tuple I64 Str)) (eff !Pure)
      (body (scan_int_loop input len start (+ start 1)))
    )

    ;; Scan a string literal starting at pos (after quote)
    (deffn (name scan_string_loop) (args (input Str) (len I64) (start I64) (curr I64)) (ret (Tuple I64 Str)) (eff !Pure)
      (body
        (if (>= curr len)
            (tuple curr (str.substring input start curr))
            (match (str.get input curr)
                (case (tag "Some" (c))
                    (if (= c 34) ;; Quote "
                        (tuple (+ curr 1) (str.substring input (+ start 1) curr))
                        (scan_string_loop input len start (+ curr 1))
                    )
                )
                (case (tag "None") (tuple curr ""))
            )
        )
      )
    )

    (deffn (name scan_string) (args (input Str) (len I64) (start I64)) (ret (Tuple I64 Str)) (eff !Pure)
      (body (scan_string_loop input len start (+ start 1)))
    )

    ;; Scan identifier or keyword
    (deffn (name scan_ident_loop) (args (input Str) (len I64) (start I64) (curr I64)) (ret (Tuple I64 Str)) (eff !Pure)
      (body
        (if (>= curr len)
            (tuple curr (str.substring input start curr))
            (match (str.get input curr)
                (case (tag "Some" (c))
                    (if (|| (is_alpha c) (|| (is_digit c) (|| (= c 95) (|| (= c 45) (|| (= c 43) (|| (= c 42) (|| (= c 47) (|| (= c 60) (|| (= c 62) (|| (= c 61) (|| (= c 46) (|| (= c 33) (|| (= c 63) (= c 58)))))))))))))) ;; alpha, digit, _, -, +, *, /, <, >, =, ., !, ?, :
                        (scan_ident_loop input len start (+ curr 1))
                        (tuple curr (str.substring input start curr))
                    )
                )
                (case (tag "None") (tuple curr ""))
            )
        )
      )
    )

    (deffn (name scan_ident) (args (input Str) (len I64) (start I64)) (ret (Tuple I64 Str)) (eff !Pure)
      (body (scan_ident_loop input len start (+ start 1)))
    )

    (deffn (name scan_comment) (args (input Str) (len I64) (pos I64)) (ret I64) (eff !Pure)
      (body 
        (if (>= pos len) pos
          (match (str.get input pos)
            (case (tag "Some" (c))
                (if (= c 10) (+ pos 1) (scan_comment input len (+ pos 1)))
            )
            (case (tag "None") pos)
          )
        )
      )
    )

    (deffn (name tokenize_rec) (args (input Str) (len I64) (pos I64) (tokens (List ast.Token))) (ret (List ast.Token)) (eff !Pure)
      (body
        (if (>= pos len)
            (cons (mk_token "EOF" "") tokens)
            (match (str.get input pos)
                (case (tag "Some" (c))
                    (if (is_whitespace c)
                        (tokenize_rec input len (+ pos 1) tokens)
                        (if (= c 59) ;; ;
                            (tokenize_rec input len (scan_comment input len (+ pos 1)) tokens)
                        (if (= c 40) ;; lparen
                            (tokenize_rec input len (+ pos 1) (cons (mk_token "LPAREN" "(") tokens))
                            (if (= c 41) ;; rparen
                                (tokenize_rec input len (+ pos 1) (cons (mk_token "RPAREN" ")") tokens))
                                (if (= c 34) ;; "
                                    (let (res (scan_string input len pos))
                                        (let (new_pos (tuple.get res 0))
                                            (let (val (tuple.get res 1))
                                                (tokenize_rec input len new_pos (cons (mk_token "STR" val) tokens))
                                            )
                                        )
                                    )
                                    (if (is_digit c)
                                        (let (res (scan_int input len pos))
                                            (let (new_pos (tuple.get res 0))
                                                (let (val (tuple.get res 1))
                                                    (tokenize_rec input len new_pos (cons (mk_token "INT" val) tokens))
                                                )
                                            )
                                        )
                                        (if (= c 38) ;; &
                                            (tokenize_rec input len (+ pos 2) (cons (mk_token "IDENT" "&&") tokens))
                                        (if (= c 124) ;; |
                                            (tokenize_rec input len (+ pos 2) (cons (mk_token "IDENT" "||") tokens))
                                            ;; Identifier / Keyword
                                            (let (res (scan_ident input len pos))
                                            (let (new_pos (tuple.get res 0))
                                                (let (val (tuple.get res 1))
                                                    (let (kind (if (|| (= val "let") (|| (= val "fn") (|| (= val "if") (= val "match")))) "KEYWORD" "IDENT"))
                                                        (tokenize_rec input len new_pos (cons (mk_token kind val) tokens))
                                                    )
                                                )
                                            )
                                        )
                                        )
                                        )
                                    )
                                )
                            )
                        )
                    )
                ))
                (case (tag "None") tokens)
            )
        )
      )
    )

    (deffn (name reverse_loop) (args (rem (List ast.Token)) (acc (List ast.Token))) (ret (List ast.Token)) (eff !Pure)
      (body
        (match rem
            (case (tag "nil") acc)
            (case (tag "cons" (h t)) (reverse_loop t (cons h acc)))
        )
      )
    )

    (deffn (name reverse) (args (l (List ast.Token))) (ret (List ast.Token)) (eff !Pure)
      (body (reverse_loop l (list-of ast.Token)))
    )

    (deffn (name tokenize) (args (input Str)) (ret (List ast.Token)) (eff !Pure)
      (doc "Tokenize Iris source into a list of tokens.")
      (body (reverse (tokenize_rec input (str.len input) 0 (list-of ast.Token))))
    )

    (deffn (name print_token_list) (args (l (List ast.Token))) (ret I64) (eff !IO)
      (body
        (match l
            (case (tag "nil") 0)
            (case (tag "cons" (h t))
                (let (_ (io.print (str.concat (str.concat h.kind ": ") h.value)))
                    (print_token_list t)
                )
            )
        )
      )
    )

    (deffn (name main) (args) (ret I64) (eff !IO)
      (doc "CLI helper that tokenizes a small sample.")
      (body
        (let (code "(let x 123 \"hello\")")
            (let (tokens (tokenize code))
                (print_token_list tokens)
            )
        )
      )
    )
  )
)
